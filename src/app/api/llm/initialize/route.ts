import { NextRequest, NextResponse } from 'next/server';
import { initializeLLM, isLlamaServerRunning } from '@/lib/gemma';
import { pingLlamaServer } from '@/lib/gemma/llama-client';

/**
 * LLMã‚µãƒ¼ãƒãƒ¼ã‚’åˆæœŸåŒ–ã™ã‚‹APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
 * POSTãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•ã‚’ãƒˆãƒªã‚¬ãƒ¼ã—ã¾ã™
 */
export async function POST(req: NextRequest) {
  console.log('ğŸŸ¢ [API Route] POST /api/llm/initialize received');
  
  try {
    // ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚’è§£æ
    const body = await req.json();
    const autoStart = body.autoStart === true;
    
    console.log(`ğŸŸ¢ [API Route] autoStart=${autoStart}`);
    
    // ã‚µãƒ¼ãƒãƒ¼ãŒæ—¢ã«å‹•ä½œã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    let serverRunning = false;
    
    // ã¾ãšãƒ—ãƒ­ã‚»ã‚¹ãƒ™ãƒ¼ã‚¹ã®ãƒã‚§ãƒƒã‚¯
    if (isLlamaServerRunning()) {
      console.log('ğŸŸ¢ [API Route] LLM server process is already running');
      serverRunning = true;
    } else {
      console.log('ğŸŸ¢ [API Route] LLM server process is not running');
    }
    
    // æ¬¡ã«HTTPãƒ™ãƒ¼ã‚¹ã®ãƒã‚§ãƒƒã‚¯ï¼ˆåˆ¥ãƒ—ãƒ­ã‚»ã‚¹ã§èµ·å‹•ã—ã¦ã„ã‚‹å ´åˆã‚‚æ¤œå‡ºï¼‰
    try {
      const isResponding = await pingLlamaServer(2, 1000);
      if (isResponding) {
        console.log('ğŸŸ¢ [API Route] LLM server is responding to HTTP requests');
        serverRunning = true;
      } else {
        console.log('ğŸŸ¢ [API Route] LLM server is not responding to HTTP requests');
      }
    } catch (pingError) {
      console.warn('ğŸŸ¡ [API Route] Error pinging LLM server:', pingError);
    }
    
    // ã‚µãƒ¼ãƒãƒ¼ãŒå®Ÿè¡Œä¸­ã§ã‚ã‚Œã°ã€åˆæœŸåŒ–ã¯ä¸è¦
    if (serverRunning) {
      console.log('ğŸŸ¢ [API Route] LLM server is already running, no initialization needed');
      return NextResponse.json({ 
        success: true, 
        initialized: false,
        status: 'already_running',
        message: 'LLM server is already running' 
      });
    }
    
    // autoStart=trueã®å ´åˆã®ã¿ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
    if (autoStart) {
      console.log('ğŸŸ¢ [API Route] Initializing LLM server...');
      const initialized = await initializeLLM();
      
      if (initialized) {
        console.log('ğŸŸ¢ [API Route] LLM server initialized successfully');
        return NextResponse.json({ 
          success: true, 
          initialized: true,
          status: 'initialized',
          message: 'LLM server initialized successfully' 
        });
      } else {
        console.error('ğŸ”´ [API Route] LLM server initialization failed');
        return NextResponse.json({ 
          success: false, 
          error: 'Failed to initialize LLM server' 
        }, { status: 500 });
      }
    } else {
      console.log('ğŸŸ¢ [API Route] Auto-start is disabled');
      return NextResponse.json({ 
        success: false, 
        initialized: false,
        status: 'not_started',
        message: 'Auto-start is disabled and LLM server is not running' 
      }, { status: 400 });
    }
  } catch (error) {
    console.error('ğŸ”´ [API Route] Error initializing LLM server:', error);
    
    const errorMessage = error instanceof Error 
      ? error.message 
      : 'Unknown error';
    
    return NextResponse.json({ 
      success: false, 
      error: errorMessage 
    }, { status: 500 });
  }
}

/**
 * LLMã‚µãƒ¼ãƒãƒ¼ã®çŠ¶æ…‹ã‚’ç¢ºèªã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
 */
export async function GET(req: NextRequest) {
  console.log('ğŸŸ¢ [API Route] GET /api/llm/initialize received');
  
  try {
    // ã‚µãƒ¼ãƒãƒ¼ã®çŠ¶æ…‹ã‚’ç¢ºèª
    let processRunning = isLlamaServerRunning();
    let httpResponding = false;
    
    try {
      httpResponding = await pingLlamaServer(1, 1000);
    } catch (pingError) {
      console.warn('ğŸŸ¡ [API Route] Error pinging LLM server:', pingError);
    }
    
    return NextResponse.json({
      success: true,
      status: {
        processRunning,
        httpResponding,
        isRunning: processRunning || httpResponding
      }
    });
  } catch (error) {
    console.error('ğŸ”´ [API Route] Error checking LLM server status:', error);
    
    const errorMessage = error instanceof Error 
      ? error.message 
      : 'Unknown error';
    
    return NextResponse.json({ 
      success: false, 
      error: errorMessage 
    }, { status: 500 });
  }
}
